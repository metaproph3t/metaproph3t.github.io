<!DOCTYPE HTML>
<html>
<head>
    <title>Proph3t's homepage</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <link media="all" href="/styles.css" type="text/css"
          rel="stylesheet" />
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@metaproph3t">
    <meta name="twitter:title" content="The human alignment problem">
    <meta name="twitter:description" content="a new name for some old ways of thinking">
</head>


<body>
<h1>Proph3t's homepage</h1>
<h2><a href="/">https://metaproph3t.github.io</a></h2>
<p>
<a href="https://themetadao.org">The Meta-DAO Project</a>
</p>

<hr />
    <div class="comp">

    <h2>The Human Alignment Problem</h2>
    <p>
    <i>Author's note: I have previously written about this topic <a href="https://medium.com/@metaproph3t/from-corporations-to-nations-how-the-meta-dao-is-going-to-change-everything-part-1-a8657562b12e">here</a>, although
	I called it 'the human coordination problem' then. This
	is my attempt to write it simpler, so that even the Emacs users among you
	can understand it ;).</i>

    <p>
    In Isaac Asimov's <i>Foundation</i> series, there's a planet called Gaia.
    On Gaia, everyone ('everyone' refers to people, animals, and even some inanimate
    matter) is part of a group consciousness. Because of this, each being does its
    best to maximize for the goals of the planet as a whole.

    <p>
    From an alignment perspective, this is an ideal planet. We can semi-formally
    state that a population <i>P</i> is aligned when each of its <i>p</i> members
    optimizes for the expected value of the population as a whole, or
    ∀p∈P, p maximizes for EV(P). 

    <p>
    Unfortunately, humans don't work like <i>p</i>s. We aren't born as machines
    that optimize for social welfare.
    Even <a href="https://www.effectivealtruism.org/">those that signal their <i>p</i> status</a>
    are often <a href="https://external-content.duckduckgo.com/iu/?u=http%3A%2F%2Face.mu.nu%2Farchives%2Fsbfwokeisafront.jfif&f=1&nofb=1&ipt=3feb4cfc586ab6983ac2c8f51973154caa9102f4b1a419b61ab099849301c70f&ipo=images">just posing</a>.

    <p>
    So we use a number of hacks to help us manage this problem. Or at least
    some of us do.
    <a href="https://www.bbc.com/news/world-africa-54690561">Somalia</a>,
    <a href="https://www.cia.gov/the-world-factbook/countries/korea-north/#economy">North Korea</a>, and
    <a href="https://en.wikipedia.org/wiki/Saparmurat_Niyazov">Turkmenistan</a>
    are some cautionary tales of failures to manage the human alignment problem.
    The three main hacks are cultures / religions,
    philosopher-kingdoms, and <a href="https://www.overcomingbias.com/p/elites-must-rulehtml">"masses-elites-experts"</a>
    institutions.

    <h3>Hack #1: Cultures and Religions</h3>
    <p>
    The most obvious approach is to try to re-program humans to be more like
    <i>p</i>s, to be more in line with the Gaian ideal. The most successful
    versions of this look something like:
    <ol>
	    <li>Figure out a good set of rules that at least rule out the most
		anti-social activities. <a href="https://en.wikipedia.org/wiki/Thou_shalt_not_kill">Thou shalt not kill</a>,
		<a href="https://en.wikipedia.org/wiki/Thou_shalt_not_steal">Thou shalt not steal</a>,
		et cetera et cetera.</li>
	    <li>Tell people that if they follow these rules, they receive some
		<i>huge</i> reward. They go to heaven. They <a href="https://islamicline.com/blog/how-many-virgins-do-you-get-in-islam-perfect-answer.html">get to sleep with virgins</a>. They <a href="https://en.wikipedia.org/wiki/Nirvana_(Buddhism)">reach enlightenment</a>.
		The grander and the less verifiable, the better. Punishment
		for not following the rules should be severe and also non-verifiable.</li>
	    <li>For those that question the epistemic roots of your rules and their
	    accordant rewards and punishments, laugh at them, <a href="https://www.biblegateway.com/passage/?search=2+Corinthians+6%3A14-17&version=ESV">ostracize them</a>, or when all else fails <a href="https://en.wikipedia.org/wiki/Spanish_Inquisition">give them a pokey pokey with a swordy swordy</a>.</li>
    </ol>

    This hack, always questionable in its effectiveness, is <a href="https://blog.oup.com/2020/12/why-is-religion-suddenly-declining/">working less and less</a> in the 21st century.

    <h3>Hack #2: Philosopher-Kingdoms</h3>
    <p>
    The second hack, invented by this guy from a long long time ago called Plato
    (credit to his parents, this is a pretty sick name), is philosopher-kingdoms.
    Plato reasoned that most people were dumb and selfish but that some people
    were smart and altruistic. According to him, we solve the alignment problem
    when we:
    <ol>
	    <li>Identify said smart and altruistic people (philosophers)</li>
	    <li>Give them all the power (make them kings)</li>
    </ol>

    The problem, of course, is that (1) is pretty hard. If 1 out of 100 people is
    smart and altruistic, even if you can sort out 90% of the bad ones you're
    still left with a 1:9 good:bad ratio.

    <h3>Hack #3: Masses elect elites who oversee experts</h3>
    <p>
    This hack takes a much more pragmatic approach. Instead of assuming that
    we'll be able to identify philosophers, this approach tries to evoke
    philosopher-like behavior from non-philosophers.

    <p>
    Since politicians are elected by people, they will be forced to serve those
    people or lose their job, or so the theory goes. Since boards of directors
    are elected by shareholders, they will be forced to serve the shareholders'
    interests or lose their job, or so the theory goes.

    <p>
    Unfortunately, the theories
    <a href="https://archive.org/details/gilens_and_page_2014_-testing_theories_of_american_politics.doc/mode/2up">are</a>
    <a href="https://hbr.org/1990/05/ceo-incentives-its-not-how-much-you-pay-but-how">wrong</a>.
    But they're also not off by so far as to make this hack unworkable. So it's
    become the predominant one in modern societies.

    <h3>Hack #4?: DAOs</h3>
    <p>
    Decentralized autonomous organizations (DAOs) are an attempt to hack around this problem using a
    <a href="https://youtu.be/pD_imYhNoQ4?si=H6pKItG9UfsmQz_D">wombo combo</a> of code
    and game theory. <a href="https://en.wikipedia.org/wiki/Bitcoin">Bitcoin</a>,
    <a href="https://molochdao.com/">Moloch DAO</a>, and
    <a href="https://themetadao.org/">The Meta-DAO</a> are examples. Since the
    design space is large, I'm going to focus my discussion on what I know
    best: the Meta-DAO. Vitalik Buterin covers the topic in greater detail
    <a href="https://blog.ethereum.org/2015/01/23/superrationality-daos">here</a>,
    if you're interested.

    <p>
    So the Meta-DAO is closer to a philosopher-kingdom than it is a 'masses-elites-specialists'
    institution. Just like a philosopher-kingdom, the Meta-DAO centralizes control
    in a hopefully-benevolent philosopher. The difference is that the philosopher
    is not a human being but a market. All of the important decisions create markets
    in assets that represent welfare, and a piece of code called 'autocrat' makes
    decisions purely based on the prices of those assets over time. If these details
    sound fuzzy, you can either read
    more 
    <a href="https://mason.gmu.edu/~rhanson/futarchy.html">here</a> and
    <a href="https://metadaoproject.github.io/docs/mechanics/implementation.html">here</a>
    or just accept that DAOs are attempts to use code and game theory to bring
    us closer to an ideal society.

    <p>
    DAOs are still in the experimental phase. We shall see whether this hack enters
    the great arc of history!

    <h3>Conclusion</h3>
    <p>
    The human alignment problem arises from a difference between how humans would
    ideally behave and how they actually behave. Historical hacks to cope with
    this problem include cultures / religions, philosopher-kingdoms, and 'masses-elites-experts'
    institutions. DAOs are a new experimental way to cope with this problem,
    possibly superior to the prior hacks.

</html>
